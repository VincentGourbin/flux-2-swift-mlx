# Tarot Style LoRA Training Configuration
# Dataset: https://huggingface.co/datasets/multimodalart/tarot-dataset
# Goal: Learn the vintage woodcut illustration style of Rider-Waite tarot cards

model:
  name: klein-4b
  quantization: int8  # Text encoder quantization (transformer always bf16)

lora:
  rank: 32
  alpha: 32.0
  target_layers: attention  # Includes Q, K, V, O projections

dataset:
  path: ./examples/tarot-style/train
  trigger_word: rwaite
  caption_format: txt

training:
  batch_size: 1
  gradient_accumulation: 1
  max_steps: 1000
  warmup_steps: 50
  learning_rate: 1e-4
  weight_decay: 0.0001
  log_every_n_steps: 10
  eval_every_n_steps: 10

loss:
  timestep_sampling: balanced  # 50/50 content/style mix
  weighting: bell_shaped       # Focus on medium noise levels

checkpoints:
  output: ./output/tarot-lora
  save_every: 250
  keep_last: 5
  learning_curve: true
  learning_curve_smoothing: 20

validation:
  every_n_steps: 250
  seed: 42
  steps: 4
  prompts:
    # WITH trigger word - should show tarot style
    - prompt: "a wizard holding a glowing staff, standing in a mystical forest"
      is_512: true
      is_1024: false
      apply_trigger: true

    # WITHOUT trigger word - should be normal style (baseline)
    - prompt: "a wizard holding a glowing staff, standing in a mystical forest"
      is_512: true
      is_1024: false
      apply_trigger: false
