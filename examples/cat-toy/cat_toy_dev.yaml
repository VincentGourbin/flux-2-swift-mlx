# Cat Toy LoRA Training Configuration - Flux.2 Dev
# Dataset: diffusers/cat_toy_example
# Trigger word: statue_cat_toy
# Use case: Subject/character LoRA with DOP (Differential Output Preservation)
#
# NOTE: Dev (32B) requires significant VRAM (~60GB with 8-bit text encoder)
# Recommended: Mac Studio M2 Ultra 128GB or equivalent
# DOP is optimized to run every 8 steps to reduce training time overhead

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
model:
  name: dev
  quantization: int8  # Text encoder (Mistral 24B) quantization

# =============================================================================
# LoRA CONFIGURATION
# =============================================================================
lora:
  rank: 32
  alpha: 32.0
  target_layers: attention  # Q, K, V, O projections only (memory-efficient for Dev)

# =============================================================================
# DATASET CONFIGURATION
# =============================================================================
dataset:
  path: examples/cat-toy/train
  trigger_word: "statue_cat_toy"

# =============================================================================
# TRAINING PARAMETERS
# =============================================================================
training:
  batch_size: 1
  max_steps: 250
  warmup_steps: 25
  learning_rate: 1.0e-4  # Standard Ostris recommendation
  weight_decay: 0.0001

# =============================================================================
# LOSS & TIMESTEP CONFIGURATION
# =============================================================================
loss:
  weighting: bell_shaped
  timestep_sampling: balanced  # Ostris balanced = 50/50 content/style
  # DOP (Differential Output Preservation) - ENABLED for subject LoRAs
  # This ensures the cat toy only appears when the trigger word is used
  diff_output_preservation: true
  diff_output_preservation_class: "cat"
  diff_output_preservation_multiplier: 1.0
  # OPTIMIZATION: For Dev, run DOP every 8 steps to reduce overhead
  # Dev is much larger (32B), so DOP forward passes are significantly slower
  # Running every 8 steps gives ~8x speedup with minimal quality impact
  diff_output_preservation_every_n_steps: 8

# =============================================================================
# MEMORY OPTIMIZATION
# =============================================================================
memory:
  gradient_checkpointing: false  # NOT YET IMPLEMENTED - requires layer-wise checkpointing
  cache_latents: true
  bucketing:
    enabled: true
    resolutions:
      - 512  # Start with lower resolution for Dev to save memory

# =============================================================================
# CHECKPOINTING
# =============================================================================
checkpoints:
  output: output/cat-toy-dev
  save_every: 125
  keep_last: 3

# =============================================================================
# VALIDATION
# =============================================================================
validation:
  prompts:
    # WITH trigger - should show the specific cat toy statue
    - prompt: "a colorful wooden cat figurine sitting on a beach"
      apply_trigger: true
      is_512: true
      is_1024: false
    - prompt: "a striped cat statue in a garden"
      apply_trigger: true
      is_512: true
      is_1024: false
    # WITHOUT trigger - should show a normal cat, NOT the statue
    - prompt: "a cat sitting on a couch"
      apply_trigger: false
      is_512: true
      is_1024: false
    - prompt: "a tabby cat on a wooden table"
      apply_trigger: false
      is_512: true
      is_1024: false
  every_n_steps: 125
  seed: 42
  steps: 28  # Dev uses 28 steps by default (not distilled)

# =============================================================================
# EMA
# =============================================================================
ema:
  enabled: false
